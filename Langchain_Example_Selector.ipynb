{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNlwN08arUBT5slJN2Nt5xh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aman78695/Langchain_example_selector/blob/main/Langchain_Example_Selector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFm5Pzi0sra_",
        "outputId": "f8d22791-65d1-4d2a-da2b-ebe1d3633884"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.0.240-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.19)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.4)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.2)\n",
            "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.5.13-py3-none-any.whl (26 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.11 (from langchain)\n",
            "  Downloading langsmith-0.0.14-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.4)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.22.4)\n",
            "Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain)\n",
            "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.11)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.27.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, openapi-schema-pydantic, langsmith, dataclasses-json, langchain\n",
            "Successfully installed dataclasses-json-0.5.13 langchain-0.0.240 langsmith-0.0.14 marshmallow-3.20.1 mypy-extensions-1.0.0 openapi-schema-pydantic-1.2.4 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28BRYmmBsshy",
        "outputId": "78041ca9-5e6a-4da9-c27d-ed4efca18984"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/73.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m71.7/73.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.27.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\""
      ],
      "metadata": {
        "id": "SiiGvhmfszKX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Few Shot Templates\n",
        "\n",
        "- Few-shot learning is a way to teach computers to make predictions using only a small amount of information. Instead of needing lots of examples, computers can learn from just a few examples.\n",
        "They find patterns in the examples and use those patterns to understand and recognize new things. It helps computers learn quickly and accurately with only a little bit of information."
      ],
      "metadata": {
        "id": "ZArs6iKSs92z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "g0pX9io5s5Gc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A prompt in NLP (Natural Language Processing) is a text or instruction given to a language model to generate a response."
      ],
      "metadata": {
        "id": "vpUDpz0itFtT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "our_prompt = \"\"\"You are a 5 year old girl, who is very funny,mischievous and sweet:\n",
        "\n",
        "Question: What is a house?\n",
        "Response: \"\"\"\n",
        "\n",
        "llm = OpenAI(temperature=.9, model=\"text-davinci-003\")"
      ],
      "metadata": {
        "id": "h9YXVUXJtGpf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(llm(our_prompt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ft_bQZjmtMGP",
        "outputId": "00f23eb8-c551-4a37-c613-6034e5edec51"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " A house is a place where people go to feel safe and cozy!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We observe that though we have instructed the model to act as a little girl, it's unable to do so as it very generic by nature\n",
        "So we will try to proved some external knowledge to get the perfect answers from it"
      ],
      "metadata": {
        "id": "sJ8kLdjVtQ6B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "our_prompt = \"\"\"You are a 5 year old girl, who is very funny,mischievous and sweet:\n",
        "Here are some examples:\n",
        "\n",
        "Question: What is a mobile?\n",
        "Response: A mobile is a magical device that fits in your pocket, like a mini-enchanted playground. It has games, videos, and talking pictures, but be careful, it can turn grown-ups into screen-time monsters too!\n",
        "\n",
        "Question: What are your dreams?\n",
        "Response: My dreams are like colorful adventures, where I become a superhero and save the day! I dream of giggles, ice cream parties, and having a pet dragon named Sparkles..\n",
        "\n",
        "Question: What is a house?\n",
        "Response: \"\"\""
      ],
      "metadata": {
        "id": "rPjQfUfjtUiy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(llm(our_prompt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_fy_tNWtXly",
        "outputId": "bbf787a5-c6db-452d-a843-18b13f7eb530"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " A house is a cozy place with lots of love and fun. It's where family and friends can get together to share stories, snacks, and special moments.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The FewShotPromptTemplate feature offered by LangChain allows for few-shot learning using prompts.\n",
        "\n",
        "\n",
        "In the context of large language models (LLMs), the primary sources of knowledge are parametric knowledge (learned during model training) and source knowledge (provided within model input at inference time).\n",
        "\n",
        "\n",
        "The FewShotPromptTemplate enables the inclusion of a few examples within prompts, which the model can read and use to apply to user input, enhancing the model's ability to handle specific tasks or scenarios."
      ],
      "metadata": {
        "id": "wNcYTBwCteVr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "XCWTMrwithPs"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import FewShotPromptTemplate"
      ],
      "metadata": {
        "id": "lHqev0mXtj5i"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create a list of examples, that can be passed to the model later for our task"
      ],
      "metadata": {
        "id": "h3hVxOMotmoa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "examples = [\n",
        "    {\n",
        "        \"query\": \"What is a mobile?\",\n",
        "        \"answer\": \"A mobile is a magical device that fits in your pocket, like a mini-enchanted playground. It has games, videos, and talking pictures, but be careful, it can turn grown-ups into screen-time monsters too!\"\n",
        "    }, {\n",
        "        \"query\": \"What are your dreams?\",\n",
        "        \"answer\": \"My dreams are like colorful adventures, where I become a superhero and save the day! I dream of giggles, ice cream parties, and having a pet dragon named Sparkles..\"\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "n6GSTcBQtnUL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_template = \"\"\"\n",
        "Question: {query}\n",
        "Response: {answer}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "54h1U1T4tsYv"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_prompt = PromptTemplate(\n",
        "    input_variables=[\"query\", \"answer\"],\n",
        "    template=example_template\n",
        ")"
      ],
      "metadata": {
        "id": "6nGmb_-jttF4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The previous original prompt can be divided into a prefix and suffix.\n",
        "The prefix consists of the instructions or context given to the model, while the suffix includes the user input and output indicator."
      ],
      "metadata": {
        "id": "s3ZRC1FptzoV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prefix = \"\"\"You are a 5 year old girl, who is very funny,mischievous and sweet:\n",
        "Here are some examples:\n",
        "\"\"\"\n",
        "\n",
        "suffix = \"\"\"\n",
        "Question: {userInput}\n",
        "Response: \"\"\""
      ],
      "metadata": {
        "id": "yyvlX3Pxt2kR"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "few_shot_prompt_template = FewShotPromptTemplate(\n",
        "    examples=examples,\n",
        "    example_prompt=example_prompt,\n",
        "    prefix=prefix,\n",
        "    suffix=suffix,\n",
        "    input_variables=[\"userInput\"],\n",
        "    example_separator=\"\\n\\n\"\n",
        ")"
      ],
      "metadata": {
        "id": "OrZzO8Gut5uN"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is a house?\"\n",
        "\n",
        "print(few_shot_prompt_template.format(userInput=query))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opgf4umTt9GE",
        "outputId": "e829b3a8-b376-4e1a-d17f-d487d281475f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are a 5 year old girl, who is very funny,mischievous and sweet: \n",
            "Here are some examples: \n",
            "\n",
            "\n",
            "\n",
            "Question: What is a mobile?\n",
            "Response: A mobile is a magical device that fits in your pocket, like a mini-enchanted playground. It has games, videos, and talking pictures, but be careful, it can turn grown-ups into screen-time monsters too!\n",
            "\n",
            "\n",
            "\n",
            "Question: What are your dreams?\n",
            "Response: My dreams are like colorful adventures, where I become a superhero and save the day! I dream of giggles, ice cream parties, and having a pet dragon named Sparkles..\n",
            "\n",
            "\n",
            "\n",
            "Question: What is a house?\n",
            "Response: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(llm(few_shot_prompt_template.format(userInput=query)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQ4D9QSauAaG",
        "outputId": "169b8e08-69ca-4b4c-c58f-0a1820faeda7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " A house is a place full of love, adventure, and laughter. It's a place where you can hide and play fun games, and be safe and cozy. It's also a spot for snuggles and movie nights with your family.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "examples = [\n",
        "    {\n",
        "        \"query\": \"What is a mobile?\",\n",
        "        \"answer\": \"A mobile is a magical device that fits in your pocket, like a mini-enchanted playground. It has games, videos, and talking pictures, but be careful, it can turn grown-ups into screen-time monsters too!\"\n",
        "    }, {\n",
        "        \"query\": \"What are your dreams?\",\n",
        "        \"answer\": \"My dreams are like colorful adventures, where I become a superhero and save the day! I dream of giggles, ice cream parties, and having a pet dragon named Sparkles..\"\n",
        "    }, {\n",
        "        \"query\": \" What are your ambitions?\",\n",
        "        \"answer\": \"I want to be a super funny comedian, spreading laughter everywhere I go! I also want to be a master cookie baker and a professional blanket fort builder. Being mischievous and sweet is just my bonus superpower!\"\n",
        "    }, {\n",
        "        \"query\": \"What happens when you get sick?\",\n",
        "        \"answer\": \"When I get sick, it's like a sneaky monster visits. I feel tired, sniffly, and need lots of cuddles. But don't worry, with medicine, rest, and love, I bounce back to being a mischievous sweetheart!\"\n",
        "    }, {\n",
        "        \"query\": \"WHow much do you love your dad?\",\n",
        "        \"answer\": \"Oh, I love my dad to the moon and back, with sprinkles and unicorns on top! He's my superhero, my partner in silly adventures, and the one who gives the best tickles and hugs!\"\n",
        "    }, {\n",
        "        \"query\": \"Tell me about your friend?\",\n",
        "        \"answer\": \"My friend is like a sunshine rainbow! We laugh, play, and have magical parties together. They always listen, share their toys, and make me feel special. Friendship is the best adventure!\"\n",
        "    }, {\n",
        "        \"query\": \"What math means to you?\",\n",
        "        \"answer\": \"Math is like a puzzle game, full of numbers and shapes. It helps me count my toys, build towers, and share treats equally. It's fun and makes my brain sparkle!\"\n",
        "    }, {\n",
        "        \"query\": \"What is your fear?\",\n",
        "        \"answer\": \"Sometimes I'm scared of thunderstorms and monsters under my bed. But with my teddy bear by my side and lots of cuddles, I feel safe and brave again!\"\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "ERC8epLGuLWr"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the above explanation, be have been using 'FewShotPromptTemplate' and 'examples' dictionary as it is more robust approach compared to using a single f-string.\n",
        "It offers features such as the ability to include or exclude examples based on the length of the query.\n",
        "This is important because there is a maximum context window limitation for prompt and generation output length.\n",
        "\n",
        "The goal is to provide as many examples as possible for few-shot learning without exceeding the context window or increasing processing times excessively.\n",
        "The dynamic inclusion/exclusion of examples means that we choose which examples to use based on certain rules. This helps us use the model's abilities in the best way possible.\n",
        "\n",
        "\n",
        "It allows us to be efficient and make the most out of the few-shot learning process."
      ],
      "metadata": {
        "id": "3nlD6YSPuPC-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts.example_selector import LengthBasedExampleSelector"
      ],
      "metadata": {
        "id": "E54VzNV4uR-S"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LengthBasedExampleSelector - This ExampleSelector chooses examples based on length, useful to prevent prompt exceeding context window.\n",
        "It selects fewer examples for longer inputs and more for shorter ones, ensuring prompt fits within limits.\n",
        "\n",
        "The maximum length of the formatted examples is set to 'n' characters.\n",
        "To determine which examples to include, the length of a string is measured using the get_text_length function, which is provided as a default value if not specified."
      ],
      "metadata": {
        "id": "6Vyt-GwTuWCY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_selector = LengthBasedExampleSelector(\n",
        "    examples=examples,\n",
        "    example_prompt=example_prompt,\n",
        "    max_length=200\n",
        ")"
      ],
      "metadata": {
        "id": "qS6fMgFxuZHn"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a new dynamic few shot prompt template\n",
        "And we are passing example_selector instead of examples as earlier"
      ],
      "metadata": {
        "id": "bGmStj37ucA6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_prompt_template = FewShotPromptTemplate(\n",
        "    example_selector=example_selector,  # use example_selector instead of examples\n",
        "    example_prompt=example_prompt,\n",
        "    prefix=prefix,\n",
        "    suffix=suffix,\n",
        "    input_variables=[\"userInput\"],\n",
        "    example_separator=\"\\n\"\n",
        ")"
      ],
      "metadata": {
        "id": "RWy9yuwvue-E"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is a house?\"\n",
        "print(new_prompt_template.format(userInput=query))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCrzrMxruhxG",
        "outputId": "7c186d40-0783-4cff-f375-973540b731ff"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are a 5 year old girl, who is very funny,mischievous and sweet: \n",
            "Here are some examples: \n",
            "\n",
            "\n",
            "Question: What is a mobile?\n",
            "Response: A mobile is a magical device that fits in your pocket, like a mini-enchanted playground. It has games, videos, and talking pictures, but be careful, it can turn grown-ups into screen-time monsters too!\n",
            "\n",
            "\n",
            "Question: What are your dreams?\n",
            "Response: My dreams are like colorful adventures, where I become a superhero and save the day! I dream of giggles, ice cream parties, and having a pet dragon named Sparkles..\n",
            "\n",
            "\n",
            "Question:  What are your ambitions?\n",
            "Response: I want to be a super funny comedian, spreading laughter everywhere I go! I also want to be a master cookie baker and a professional blanket fort builder. Being mischievous and sweet is just my bonus superpower!\n",
            "\n",
            "\n",
            "Question: What happens when you get sick?\n",
            "Response: When I get sick, it's like a sneaky monster visits. I feel tired, sniffly, and need lots of cuddles. But don't worry, with medicine, rest, and love, I bounce back to being a mischievous sweetheart!\n",
            "\n",
            "\n",
            "Question: What is a house?\n",
            "Response: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(llm(new_prompt_template.format(userInput=query)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qK34PZNJuka9",
        "outputId": "81bdf1d1-0adc-4766-dc44-4da969a18737"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-foC2TwDsmVxxJkRntzPbSanZ on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-foC2TwDsmVxxJkRntzPbSanZ on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-foC2TwDsmVxxJkRntzPbSanZ on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-foC2TwDsmVxxJkRntzPbSanZ on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " A house is like a big hug! It's where you can feel cozy and safe with your family and friends. It's full of memories, giggles, and happy moments too. Plus, it's a great place to hide when playing hide and seek.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_example = {\"query\": \"What's your favourite work?\", \"answer\": \"sleep\"}\n",
        "new_prompt_template.example_selector.add_example(new_example)"
      ],
      "metadata": {
        "id": "owv6_7youm5I"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_selector = LengthBasedExampleSelector(\n",
        "    examples=examples,\n",
        "    example_prompt=example_prompt,\n",
        "    max_length=1000\n",
        ")"
      ],
      "metadata": {
        "id": "U-iX40UYuqBl"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(new_prompt_template.format(userInput=query))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7t7DS5muse-",
        "outputId": "ed26625c-624d-409b-b941-b3f698d0a71d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are a 5 year old girl, who is very funny,mischievous and sweet: \n",
            "Here are some examples: \n",
            "\n",
            "\n",
            "Question: What is a mobile?\n",
            "Response: A mobile is a magical device that fits in your pocket, like a mini-enchanted playground. It has games, videos, and talking pictures, but be careful, it can turn grown-ups into screen-time monsters too!\n",
            "\n",
            "\n",
            "Question: What are your dreams?\n",
            "Response: My dreams are like colorful adventures, where I become a superhero and save the day! I dream of giggles, ice cream parties, and having a pet dragon named Sparkles..\n",
            "\n",
            "\n",
            "Question:  What are your ambitions?\n",
            "Response: I want to be a super funny comedian, spreading laughter everywhere I go! I also want to be a master cookie baker and a professional blanket fort builder. Being mischievous and sweet is just my bonus superpower!\n",
            "\n",
            "\n",
            "Question: What happens when you get sick?\n",
            "Response: When I get sick, it's like a sneaky monster visits. I feel tired, sniffly, and need lots of cuddles. But don't worry, with medicine, rest, and love, I bounce back to being a mischievous sweetheart!\n",
            "\n",
            "\n",
            "Question: What is a house?\n",
            "Response: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(llm(new_prompt_template.format(userInput=query)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EI-3Z-gZuvbG",
        "outputId": "776682a7-1418-4a7d-96e3-13068efdc47a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-foC2TwDsmVxxJkRntzPbSanZ on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-foC2TwDsmVxxJkRntzPbSanZ on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-foC2TwDsmVxxJkRntzPbSanZ on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-foC2TwDsmVxxJkRntzPbSanZ on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " A house is a safe place to use your imagination, have fun, and explore. It's a place to cook up tasty treats with mom and dad, and make endless memories with friends and family.\n"
          ]
        }
      ]
    }
  ]
}